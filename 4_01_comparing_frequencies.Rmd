# Working with frequencies

## Introduction

Much of the time in biology we are dealing with whole objects (plants, animals, cells, eggs, islands, etc.) or discrete events (attacks, matings, nesting attempts, etc.). We are often interested in making measurements of numeric variables (length, weight, number, etc.) and then either comparing means from samples (e.g. mean leaf size of plants from two habitat types), or investigating the association between different measurements (e.g. mean leaf size and herbivore damage).

However, we sometimes find a situation in which the ‘measurement’ we are interested in is not a quantitative measure (i.e. is not on a ratio or interval, scale), but is *categorical*. You will recall that categorical data are things like sex, colour or species. Such variables cannot be treated in the same way as numeric variables because although we can ‘measure’ each object (e.g. record if an animal is male or female), obviously we can’t calculate numeric quantities such as the ‘mean colour morph’, ‘mean species’ or ‘median sex’ of animals in a sample.

## A new kind of distribution

There are a quite a few of options for dealing with categorical data^[e.g. the 'log-linear model', 'Fisher's exact test', and the 'G-test'.]. We're just going to look at one option in this book: $\chi^2$ tests. This is pronounced, and sometimes written, 'chi-square'.^[The 'ch' is a hard 'ch', as in 'character'.]. This isn't necessarily the best approach for every problem, but $\chi^2$ tests are widely used in biology so they are a good place to start.

```{r, echo=FALSE}
data.frame(Chi_2 = rchisq(5e5, df = 1)) %>%
  ggplot(aes(x = Chi_2)) + geom_histogram(binwidth = 0.4) + 
  coord_cartesian(xlim = c(0, 10))
```

## Types of test

Although the tests all work on the same general principle, and all use the same statistic, it is helpful to distinguish two sorts of $\chi^2$ tests:

### $\chi^{2}$ **goodness of fit test**. 

A goodness-of-fit test is applicable in a situation where we have a single categorical variable (with any number of categories in it) and some hypothesis from which we can predict the expected proportions of observations falling in each category. For example... 

We might be interested in whether the number of males is equal to the number of females among second year students doing biology at Sheffield. We could record the numbers of males and females in a cohort, ending up a sample containing one nominal variable (Sex) with two only categories (Male and Female). We want to know if there is any evidence for sex-related bias in the decision to study biology. Based on information about human populations, we know that the sex ratio among 18 year olds is fairly close to 1:1^[Human sex-ratio is actually slightly biased toward males at birth, but since males experience a higher mortality rate in their teens, the sex ratio among 18 year olds is closer to 1:1]. We are thus able to compare the goodness of fit of the number of males and females in a sample of students with the expected value predicted by the 1:1 ratio. 

If we had a total of 182 students we might get this sort of table:

               Male   Female
------------ ------- --------
**Observed**    81      101

With a 1:1 sex ratio, if there is no sex-bias in the decision to go to university and to study biology, we would expect 91 of each sex. In this case it looks as though there may be some discrepancy between the expected values and those actually found. However, this discrepancy could be entirely consistent with sampling variation---perhaps females are no more likely to choose biology and we ended up with a higher proportion of female students by chance. The $\chi^{2}$ goodness of fit test allows us to test how likely it is that such a discrepancy has arisen by chance.

2.  $\chi^{2}$ **contingency table test**. A contingency table test is applicable in a situation where each object is classified according to more than one categorical variable. Contingency table tests are usually used to test whether there is an association (or conversely, independence) between the variables. 

### The assumptions and requirements of $\chi^{2}$ tests

It's important to realise that in terms of the assumptions they rely on, contingency table and goodness-of-fit tests arn't fundamentally different from one another. The difference between the two types lies in the type of hypothesis tested by each. The only real difference is that the when we carry out a goodness-of-fit test we have to supply the expected values, whereas the calculation of expected values is embedded in the formula used to carry out a contingency table test. That will make more sense once we've seen the two test in action...

$\chi^{2}$ tests are often characterised **non-parametric** tests because they do not assume any particular form for the distribution of the data. In fact, as with any statistical test, there are some assumptions, but these are relatively mild:

*   The data are independent counts of objects or events which can be classified into mutually exclusive categories. 

*   The expected counts are not very low. The general rule of thumb is that the expected values should be greater than 5.

(We'll explain exactly what we mean by 'expected values' later)

The most important thing to remember about $\chi^{2}$ tests is that they must always be carried out on the actual counts. Although the $\chi^{2}$ is really telling us how the proportions of objects in categories vary, the analysis should never be carried out on the percentages or proportions, only on the original count data. Similarly, $\chi^{2}$ cannot be used with means.






