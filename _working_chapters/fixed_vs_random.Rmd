(N.B. In the case of a more complex design than this using blocks (with more than one treatment in addition to the blocks) it there is an additional complication we have to consider: the question of whether the block effects are what is termed *fixed* or *random*. The issue of random and fixed effects is explained in a little more detail in this week's extra reading, but often with randomised block designs, it is
appropriate to treat the blocks as random factors. In the case of a simple design like this one (just one treatment and one set of blocks) we do not have to make that decision as the results are the same in either case.)

## Random and fixed effects.

Usually the treatments you encounter in ANOVA are what are termed fixed effects---i.e. they are decided on by the investigator, not just sampled randomly from all possible levels of the treatment.  However, sometimes you want to analyse differences between 'levels' of a treatment where in fact the different levels are random---e.g., if you are testing to see if recovery time after a particular operation is affected by the age of the patient, and whether it varies between hospitals, you might randomly select 6 hospitals and find recovery times for 10 patients from each of three different age groups.  The hospitals are one factor in your analysis, age is the other.  Age is a fixed effect (you selected particular age groups) but hospitals are a random effect. You didn't select particular different sorts of hospitals, because all you really want to understand is the among hospital variation. In a one-way ANOVA (if you were just looking at hospitals) this makes no difference, but in a two-way ANOVA it can affect the way the significance test is calculated. If you think you may have a situation requiring a random effects framework, consult a statistics text.

A model that includes both random and fixed effects is sometimes called a 'mixed model'. There is a huge, and rather technical, literature about these kinds of models. These are relatively easy to fit using R but can be hard to work with. For example, extracting reliable *p*-values out of a mixed model is not always a simple task. One piece of advice might help though: try to design a balanced experiment. If you can do this the calculations are not too bad.

```{block, type='warning-box'}
#### Random and fixed effects can get confusing

A common question is, "should I use a fixed or random effects model?". The problem with this question is that these terms do not have widely agreed-upon definitions. People use particular definitions of fixed and random effects without necessarily realising that there are a range of different definitions in the literature. Keep this in mind if you find yourself asking for advice about fixed vs. random effects; it is not uncommon to receive seemingly contradictory advice from different people because they think about the terms in slightly different ways.
```

(N.B. In the case of a more complex design than this using blocks (with more than one treatment in addition to the blocks) it there is an additional complication we have to consider: the question of whether the block effects are what is termed *fixed* or *random*. The issue of random and fixed effects is explained in a little more detail in this week's extra reading, but often with randomised block designs, it is
appropriate to treat the blocks as random factors. In the case of a simple design like this one (just one treatment and one set of blocks) we do not have to make that decision as the results are the same in either case.)
