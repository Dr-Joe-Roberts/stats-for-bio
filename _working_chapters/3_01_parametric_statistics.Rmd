# Parametric statistics

## Introduction

The majority of statistical tools we use in this book share one important feature: they are all underpinned by a mathematical model of the populations involved. Because a mathematical model of some kind is always lurking in the background, this particular flavour of statistics is known as **parameteric statistics**. The word 'parametric' in this context simply refers to the fact that the behaviour of a mathematical model is defined by one or more quantities, known as 'parameters'.

We aren't going to study the mathematical details of these models in any great detail; after all, this isn't a maths book. However, there are a few key results that are good to know about, for two reasons:

1.   It is important to at least consider the **assumptions** underlying the models we'll be using. Mathematical assumptions are essentially aspects of a system that we accept as true, or at least nearly true. If these aren't reasonable for a given situation, we can't be sure that the results of the corresponding analysis (e.g. a statistical test) will be reliable. They might not be true of course, which is why it is important to always evaluate our assumptions.

2.    We explored a number of key concepts from fequentist statistics in the last few chapters, such as sampling variation, null distributions, and *p*-values. These ideas will crop up time and time again throughout the book. We want ensure that we can 'connect the dots'. That is, we want to understand, in rough terms at least, how the models and their assumptions lead to particular statistical tests.

## Mathematical models {#math-models}

$$y_i = \text{Systematic Component} + \text{Random Component}$$

$$y_i = a + \epsilon_i$$

## The normal distribution {#parametric-stats}

In this course, this assumption is essentially always the same: we assume that the error part of the model follows a **normal distribution**. If you studied A-level statistics you should know all about this. If not, you may have come across it without realising: the normal distribution is sometimes called the 'Gaussian distribution' or more colloquially, 'the bell-shaped curve'.

Unfortunately, we don't have enough time in this course to really study the normal distribution in much detail. There are however, many good online resources to help you learn you about it if you want to know more. Here is one relatively non-technical introduction:

http://onlinestatbook.com/2/normal_distribution/normal_distribution.html

## Taking samples from normal distributions

## Calculating standard errors

One sample...

$$\frac{s}{\sqrt{n}}$$

Difference between samples with equal variance and sample size...

$$\sqrt{\frac{s_1^2+s_2^2}{n}}$$

## The *t* distribution

A statistician called W.G. Gosset showed that when we take samples from a normally distributed variable and calculate estimates of the population mean, the sampling distribution of these means has a particular form---it follows a Student's *t*-distribution^[Why is it called Student's *t*? The *t*-distribution was discovered by W.G. Gosset, a statistician employed by the Guinness Brewery. He published his statistical work under the pseudonym of 'Student', because Guinness would have claimed ownership of his work if he had used his real name.].

This 

The same is true if you take two samples from a normal distribution, calculate their means, and then subtract these from one another. The sampling distribution of the *differences between estimates of means* also follows a Student's t-distribution.



