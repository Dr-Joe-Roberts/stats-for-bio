# Populations and samples

> Statistics is the science of learning from data, and of measuring, controlling, 
> and communicating uncertainty; and it thereby provides the navigation essential 
> for controlling the course of scientific and societal advances
> 
> [Davidian and Louis (2012)](https://doi.org/10.1126/science.1218685)


## Populations and samples {#pops-and-samps}

The word '**population**' has much a wider meaning in statistics than it does in biology. When a biologist talks about a population they are referring to a group of individuals of a particular species who interbreed. In statistics, a population is any group of items that share certain attributes or properties. For example, the population of APS students have a common interest in biology, they are mostly in their late teens and early 20s, and they tend to have similar educational backgrounds. Another example is the moorland habitat of the UK. There are many moorland sites in the UK. Although their ecology varies from one location to the next, they are all similar in certain respects, i.e., they are primarily characterised by low-growing vegetation and acidic soils. A population of organisms--as defined by biologists--can also be considered to be a statistical population. 

Very often, the primary goal of a statistical analysis to learn something about a population of interest to the investigator (i.e., you!). The 'something' could be just about anything we know how to measure or characterise. For example, a social scientist might be interested in understanding the political attitudes of university students. An ecologist studying climate change impacts in the UK might want to know how much carbon is locked up peatland areas. These are very different questions, but there are fundamental commonalities in how they can be addressed using statistical ideas. 

#### Decide which variables are you interested in

The first step is to decide which features of the focal population you are interested in learning about. In essence this comes down to the question, Which variable (or variables) do I need to measure to address my research question? In the examples above, these would be things like, a standardised measure of political attitude, the mass of carbon stored per unit area, or the body mass of individuals in a biological population. Sometimes we are interested in more than the properties of individual variables. Instead, we might want to understand the relationship between two or more variables.

#### Decide which population parameters are relevant

Next, we have to decide which **population parameter** associated with the focal variable is relevant. A population parameter is a numeric quantity that describes an aspect of the focal variable's distribution in the population. We touched on the idea of a distribution last year: in statistics, a distribution is a statement about the frequency with which different values of a variable are observed. The mean and variance of a population are both examples of population parameters. These describe the central tendancy ('which values are most common?') and the dispersion ('how variable are the values') of a distribution.

Most often, we want to learn something about the population mean, because this allows us to answer questions such as 'how many are there?' or 'how much of something is present?'. Other population parameters can be relevant too though. For example, the goal of statistical genetics is to partition variablity among individuals, i.e., we want to know how much phenotypic variation is due to genetic vs. non-genetic sources. In this case, it is the population variance that we want to learn about (look over last year's course if you can't remember what variance is). Finally, if we are trying to learn about how two variables are associated, then a population correlation coefficient might be the right parameter to focus on.

#### Gather a sample

In the the type of statistics that we use in this course (called, 'frequentist statistics'), the population parameters are considered to be fixed, but unknown quantities. Our goal is to learn about them by collecting data. If we could measure every object in the focal population we wouldn't need statistics. We would just calculate whatever quantity we needed to know and we'd be done. Of course, in the real world we face all kinds of resource constraints--we have limited time and money to invest on any given problem, no matter how important it is--so we can only study a small **sample** of the population. 

A sample is just a subset of the wider population, which has been chosen so that it is representative of that population. The word 'representative' is very important in this context. For example, if we want to understand the reproductive characteristics of our favourite study species, but we have only sampled young or old individuals, it will be very difficult to generalise our findings to the wider population. This is because the reproductive performance of most organisms changes as they age. If we only measure young individuals, we haven't learnt anything about older individuals, and vice versa.

Sampling theory is a large subdiscipline of statistics. We will touch a few of the important ideas about sampling as we go through this course. For now, we will just assume that we know how to collect samples that are representative of the population.

#### Use the sample to learn about the population.

Once we have a representative sample, we will often want to calculate a **point estimate** of the population parameter of interest. A point estimate (sometimes called a **statistic**) is just a single value that represents our 'best guess' of the true value of the unknown population parameter. If we are interested in the population mean, for example, then the obvious estimate to use is the sample mean. This is just 'the mean' you learned how to calculate at school.

(By the way, people often just say 'estimate' instead of 'point estimate', because writing 'point estimate' all the time becomes tedious.)

However, a single point estimate of a population parameter is virtually useless on its own. Remember, an estimate is derived from a limited sample of the wider population. Even if we are very careful about how we sample the population, there is no way to guarantee that the composition of the resulting sample exactly matches that of the population. This means that any estimate we derive from a sample will be imperfect, in the sense that it won't exactly match the true, unknown population value. 

Luckily, we can use the machinery of statistics to help us characterise this uncertainty. Today's practical will give you a flavour of the important ideas.

## Sampling error {#sampling-error}

```{r plant-sim-par, echo=FALSE}
set.seed(27081975)
nsamp <- 200
sampsize1 <- 20
sampsize2 <- 40
sampsize3 <- 80
index <- c(1,1,2,2,2)
prop.purp <- sum(index==1)/length(index)
```

The easiest way to get a sense of how population parameters and their estimates are related to one another is to use computer simulation. A simulation is just an imitation of a real-world process. It is very easy to simulate the process of sampling from a population in R.

Here is a concrete example. Let's assume that we are working with a plant species that exists as two different morphs: a purple morph and a green morph. To study this aspect of the population we would need to collect information about the colour of different individuals, which means we are working with a nominal variable (taking values 'purple' or 'green'). We are interested in a very simple question: What is the frequency of the purple morph? That is, we want to know what percentage (or equivalently, what proportion) of the population is purple. The population parameter of interest is therefore, morph frequency. 

Here is a visual depiction of the problem, which that shows where purple and green individuals are located on a hypothetical landscape:
```{r plants-all, echo = FALSE}
plantdata <- 
  data.frame(xloc  = runif(nsamp), 
             yloc  = runif(nsamp), 
             morph = sample(c("purple","green")[index], 100, replace = TRUE))
plttheme <- theme_get()
plttheme$axis.text <- plttheme$axis.ticks <- plttheme$axis.title <- element_blank()
baseplt <- ggplot(plantdata, aes(x = xloc, y = yloc, colour = morph, )) + 
           geom_point() + scale_color_identity() + coord_fixed() + plttheme
baseplt
```

These artificial, idealised data were generated using R. We placed 'individuals' onto the landscape at random locations---every location is equally likely---and then assigned them purple morph status with a probability of 0.4 (we made them are green otherwise).

#### Sampling error and sampling distributions

In contrast to a real-world setting, we already know the true value of the population parameter in this example; the purple morph frequency is 40%. However, if we didn't know 'truth', and we weren't in a position to sample every individual, we would have to construct some kind of point estimate of the purple morph frequency. To do this, we could take a representative sample of plants from across the landscape and then calculate the percentage of purple plants in our sample. A representive sample in this case is one in which every individual has an equal probability of being sampled. We call this a **random sample**. Gathering a random sample of organisms from across a landscape is surprisingly hard to do in reality. Luckily, it is at least easy to simulate a random sample.

Let's seen what happens if we sample `r sampsize1` plants in this way. This plot shows the original population of plants, but now we have circled the selected individuals in red.
```{r plants-samp1, echo = FALSE}
sample1 <- sample_n(plantdata, size = sampsize1)
baseplt + geom_point(data = sample1, colour = "red", shape = 1, size = 5)
freqs1 <- table(sample1$morph)
```
We found `r freqs1["green"]` green plants and `r freqs1["purple"]` purple plants in this first hypothetical sample, which means our estimate of the purple morph frequency is `r round(100*freqs1["purple"]/sampsize1)`%. This is not far off the true value of 40%. What happens if we repeat this process, resulting in a new, completely independent sample? Here is the sampled population:
```{r plants-samp2, echo = FALSE}
sample2 <- sample_n(plantdata, size = sampsize1)
baseplt + geom_point(data = sample2, colour = "red", shape = 1, size = 5)
freqs2 <- table(sample2$morph)
```
This time we ended up sampling `r freqs2["green"]` green plants and `r freqs2["purple"]` purple plants, so our new estimate of the purple morph frequency is `r round(100*freqs2["purple"]/sampsize1)`%, which is quite some way off the true value.

Nothing about the study population changed between the first and second sample. What's more, we used a completely reliable sampling scheme to generate these samples; there is nothing biased or 'incorrect' about the way individuals were sampled. The different estimates of the purple morph frequency arise from nothing more than chance variation.

This chance variation--which arises whenever we observe a sample instead of the whole population--has a special name. It is called the **sampling error** (or sampling variation). Sampling error is the main reason we have to use statistics to learn from data. It is always present, and so any estimate you derive from a sample is affected by it. Sampling error is not a property of any particular sample. It is really a property of the population distribution of the focal variable, and the sampling method used to investigate this. That statement may seem a little cryptic now, but we will start to get a sense of what it means in this, and the next, practical.

We can develop our simple simulation example to explore the consequences of sampling error. Rather than taking one sample at a time, we will use R to simulate 1000s of different samples, and for each sample, calculate the number of purple morph individuals found. Each sample is drawn from the same population, i.e., the population parameter (purple morph frequency) is the same for every sample. Here is a summary of one such repeated simulation exercise:
```{r samp-dist-1, fig.height=3, fig.width=6, echo = FALSE}
out <- data.frame(n.purple = factor(rbinom(n = 100000, size = sampsize1, prob = prop.purp)))
ggplot(out, aes(x = n.purple)) + geom_bar() + 
  scale_x_discrete(limits = as.character(0:sampsize1)) + 
  xlab("No. of purple morph individuals") + ylab("Count")
```

This bar plot summarises the result from 100000 samples. In each sample, we took `r sampsize1` individuals from our hypothetical population and calculated the number of purple morphs found. The bar plot shows the number of times we found 0, 1, 2, 3, ... purple individuals, all the way up to the maximum possible (`r sampsize1`). It summarises the distribution of purple morph counts that we can expect when we repeat the same sampling process over and over again.

This distribution has a special name. It is called the **sampling distribution**. The sampling distribution is just the distribution we expect a particular statistic to follow. In order to to work this out, we have to postulate values for the population parameters, and we have to know how the population was sampled. We just used simulation to approximate the sampling distribution of purple morph counts that arises when we sample `r sampsize1` individuals from a population that is `r 100*prop.purp`% purple. 

<div class="exercise-box">
#### Exercise: Sampling distributions
<div class="box-text">
Spend a few minutes looking at the distribution of purple morph counts we just simulated. See if you can answer the following questions:

*   What is the most common purple morph count we should expect to find in a sample of 20 individuals, when the population frequency is thought to be 40%?

*   Imagine someone told you that they thought 40% of the plants were purple. If you sampled 20 individuals and found that 4 of them were purple, would you be convinced of their assertion? What if you found only 2 purple plants?
</div>
</div>

The sampling distribution is the key to 'doing statistics'.  

Once we know how to calcualte the sampling distribution for a particular problem, we can start to make statements about sampling error (to quantify uncertainty), and we can begin to make meaningful comparisons that enable us to address scientific questions. Fortunately, we don't have to work any of this out for ourselves. Statisticians have already done this for many different situations.

#### The effect of sample size

Perhaps the most important property of any sampling scheme is the **sample size**: the number of observations (objects or items) in a sample. To see how sample size influences the sampling distribution, and to understabnd why it matters, let's carry on with our simulation example. We will repeat the resampling exercise, but this time we will do it twice, first taking a sample of `r sampsize2` individuals each time, and then taking a sample of `r sampsize3` individuals each time. In both cases, we'll examine the results of taking 100000 samples overall:

```{r samp-dist-2, fig.height=3, fig.width=6, echo = FALSE}
out <- data.frame(n.purple = factor(rbinom(n = 100000, size = sampsize2, prob = prop.purp)))
ggplot(out, aes(x = n.purple)) + geom_bar() + 
  scale_x_discrete(limits = as.character(seq(0, sampsize2, 1)), 
                   breaks = as.character(seq(0, sampsize2, 2))) + 
  xlab("No. of purple morph individuals") + ylab("Count")
```

```{r samp-dist-3, fig.height=3, fig.width=6, echo = FALSE}
out <- data.frame(n.purple = factor(rbinom(n = 100000, size = sampsize3, prob = prop.purp)))
ggplot(out, aes(x = n.purple)) + geom_bar() + 
  scale_x_discrete(limits = as.character(seq(0, sampsize3, 1)), 
                   breaks = as.character(seq(0, sampsize3, 4))) + 
  xlab("No. of purple morph individuals") + ylab("Count")
```

What do these plots tell us about the effect of increasing sample size? Notice that we plotted each of them over the full range of possible outcomes (the x axis runs from 0-`r sampsize2` and 0-`r sampsize3`, respectively, in the first and second plot). We did this so that we can meaningfully compare the spread of each sampling distribution, relative to the full range of possible outcomes.

What do these figures show? The range of outcomes in the first plot is roughly 6 to 26, which corresponds to estimated frequencies of the purple morph in the range of 15-65% (we sampled 40 individuals each time). The range of outcomes in the second plot is roughly 16 to 48, which corresponds to estimated frequencies in the range of 20-60%. Clearly, this suggests that when we increase the sample size we expect to encounter less sampling error. This makes intuitive sense: the composition of large sample should more closely approximate that of the true population than a small sample. 

How much data do we need to collect to accurately estimate a frequency? Here is the approximate sampling distribution of the purple morph frequency estimate when we sample `r (sampsizebig <- 500)` individuals each time we take a sample: 
```{r samp-dist-big, fig.height=3, fig.width=6, echo = FALSE}
out <- data.frame(n.purple = factor(rbinom(n = 100000, size = sampsizebig, prob = prop.purp)))
ggplot(out, aes(x = n.purple)) + geom_bar() + 
  scale_x_discrete(limits = as.character(seq(0, sampsizebig, 1)), 
                   breaks = as.character(seq(0, sampsizebig, 50))) + 
  xlab("No. of purple morph individuals") + ylab("Count")
```

Now the range of outcomes is about 160 to 240, corresponding to purple morph frequencies in the 32-48% range. This is a big improvement over the smaller samples that we just considered, but even with 500 individuals in a sample, we should still expect quite a lot of uncertainty in our estimate. The take home message is that you need a lot of data to reduce sampling error.

### The standard error

So far, we have been fairly relaxed about how we quantified the variability in a sampling distribution. We just extracted the approximate range of purple morph counts by eye. There is a better quantitative measure of this variability though. It is called the **standard error**. The standard error is actually quite a simple idea, but its definition can be confusing. The standard error is the standard deviation of the sampling distribution of a statistic such as a mean (or frequency). It measures the expected spread, or dispersion, of the sampling distribution. It is common to use the shorthand SE or s.e. in place of 'standard error'.

We can use a simulation in R to calculate the (approximate) standard error of purple morph frequencies. For example, if we want to know the standard error when we use a sample size of 20, and the purple morph frequency is 40% (i.e., the proportion of purple morph plants is 0.4), we can use this snippet of R code:
```{r}
purple.prob <- 0.4
sample.size <- 20
samples <- 100 * rbinom(n = 100000, size = sample.size, prob = purple.prob) / sample.size
sd(samples)
```
You **do not** have to understand exactly how this works, but if you did A-level statistics you might be able to guess what the `rbinom` function is doing. Essentially, what we did was to simulate the percentage of purple morph individuals found in 100000 samples of 20 individuals (stored in `samples`), and then used the `sd` function to calculate the standard error--remember, the standard error is the standard deviation of the sampling distribution of a statistic (= morph frequency). Ask a demonstrator if you want to know more. We just want you to use this R code to do the next exercise.

<div class="exercise-box">
#### Exercise: How does sample size influence the standard error?
<div class="box-text">
Use the above code to vary the sample size from 20 to 320, doubling the sample size each time (i.e., use samples of 20, 40, 80, etc). You only need to vary the value of `sample.size` to do this. Make sure you do this in your script, not at the command line. If you are feeling ambitious, store the results of your investigation in a data frame and use `ggplot2` to help you visualise them. You don't have to do this though; it is fine just to write down the numbers.

See if you can work out how the standard error changes as the sample size increases. Does the standard error halve when you double the sample size, or is the relationship more complicated? If you think the relationship is more complicated, what form does it take?
</div>
</div>

The last exercise should have convinced you that the standard error decreases as the sample size is increased. We already knew that though. The more important insight relates to the form of this relationship. What you should have noticed is that doubling the sample size does not halve the standard error. In fact, doubling the sample size only changes the standard error by a factor of 1/√2, which is less than 1/2 (don't worry if you did not spot this).

The somewhat depressing conclusion from this investigation is that we have to increase the size of a sample by a factor of 4 to halve the uncertainty associated with an estimate of a population parameter. This result isn't a peculiarity of the morph frequency example; it is very general.

## Quantifying uncertainty of an estimate {#uncertainty}

```{r, echo = FALSE, eval = FALSE}
set.seed(27081975)
nsample <- 25
prpszs <- rnorm(nsample, mean = 700, sd = 150) + 20
grnszs <- rnorm(nsample, mean = 740, sd = 160) 

pmorph <- c("purple","green")[rep(1:2, each = nsample)]
morph.weights <- data.frame(pmorph = pmorph, 
                             weight = round(c(prpszs, grnszs)))

write.csv(morph.weights, row.names = FALSE,
          file = "./course-data/MORPH_WEIGHTS.CSV")
```

By this point you might (quite reasonably) be wondering why we have spent so much time looking at the properties of repeated samples from a population with known parameters. After all, when we collect real data we only have a single sample to work with. We also won't know much about the population parameter of interest; this lack of knowledge is the reason for collecting the data in the first place!

The short answer to this question is that we want to learn how to use '**frequentist inference**' in this course. The word 'inference' is just statistical jargon for the process of learning about a system using data. A precise definition of what constitutes frequentist inference is well beyond the scope of this course, but we can give a rough description. Frequentist inference works by asking *what would have happened* if we were to repeat an experiment or data collection exercise many times, assuming that the a population parameter is fixed at a particular value. The precise choice of population parameter to use, and its 'particular value', will depend on what kind of question you are asking of the data.

### A new example {}

In order to get a sense of how all this works, we are going to finish today's practical by addressing a very simple question: How precise is an estimate of the population mean? We'll look at this question in two different ways, both of which rely on 'frequentist' ideas.

Once again, we'll investigate the problem by working through a simple example. We will stay with the purple morph / green morph example, but this time we'll examine a different variable: the dry weight biomass of our imaginary plants. Perhaps we suspect that the two morphs have different growth habits. One way to address this hypothesis would be to measure the biomass of individuals of each morph (though arguably, this is a little naive). Ultimately, we want to compare the biomass of each morph, but that is the goal of the next practical. Today, we'll just see how to quantify uncertainty in a single estimate of the population mean biomass of each morph.

In order to study the biomass of individuals in our hypothetical population, we would collect a sample of dry weights. Dry weight is a numeric variable, measured on a ratio scale. The population parameters of interest now are the population mean dry weights of each morph. Notice that our definition of 'the population' is slightly different than before. Now we are imagining that each morph is a seperate population. Let's assume that we have sampled the dry weight (in grams) of 25 representative individuals of each morph.

We have have generated a dataset to represent this situation, stored in a Comma Seperated Value (CSV) text file called 'MORPH_WEIGHTS.CSV'. 

<div class="exercise-box">
#### Exercise: Investigate the dataset
<div class="box-text">
Download the MORPH_WEIGHTS.CSV file from MOLE and place it in your working directory (this is the location you set at the beginning of this practical). Next, make sure that you can do the following:

* Read the data in MORPH_WEIGHTS.CSV into an R data frame using `read.csv`, assigning the data frame the name `morph.weights`.

(Hint: Use RStudio to help you do this. In the 'Environment' tab there is a dropdown menu called 'Import Dataset'. Click on this, select 'From Text File...', click on the MORPH_WEIGHTS.CSV file, and then then change the suggested name to 'morph.weights'. You should then need to copy the `read.csv` command that RStudio sends to the Console into your script.)

* Use the `glimpse` function from `dplyr` to inspect the structure of `morph.weights`. How many variables are in the dataset. What are their names? What kind of variables are they?

* Use the `View` function to inspect the data. How many rows are in the dataset--does this number make sense to you? Are the values of the different variables as you would expect them to be?
</div>
</div>

```{r, echo = FALSE}
morph.weights <- read.csv(file = "./_data_files/MORPH_WEIGHTS.CSV")
```

We read in the data and then carried out a few 'sanity checks' in that last exercise. **Always check your data after you have read it in**. There is no point messing about with the likes of `dplyr` and `ggplot2`, or carrying out a statistical analysis, until we have done this. If we don't understand how our data is organised, there is very real risk that we will make a lot of easily avoidable mistakes.

The next step is to calculate some simple descriptive statistics for each morph. We need to know the sample means--these are our 'best guesses' of the population means--and it may be useful to know something about the variability of the samples. The sample standard deviation is a good measure of the latter. Here is a reminder of how to do this using `dplyr`:
```{r}
temporary <- group_by(morph.weights, pmorph)
summarise(temporary, mean = mean(weight), stan.dev = sd(weight))
```
This shows that the mean dry weights of purple and green morphs are 658 grams and 787 grams, respectively. The standard deviation estimates from the two samples suggest that dry weights of green morphs are a little more variable than the purple morphs. 

By the way, if you like using the `%>%` operator to chain together `dplyr` functions (the 'verbs'), then here is how to use this to achive exactly the same result as above:
```{r}
morph.weights %>% 
  group_by(pmorph) %>% 
  summarise(mean = mean(weight), stan.dev = sd(weight))
```

Using means and standard deviations to summarise samples can be tricky to understand until you are used to them. A plot of some kind is much more useful. At the moment, we are just trying to understand the distribution of our two samples. One way to do this is to construct a histogram or a dotplot of each sample distribution. We don't have much data, so a dotplot is probably the best option. Here is one way to make a dot plot for just the purple morph data:
```{r purple-dist}
purp.weights <- filter(morph.weights, pmorph == "purple") 
ggplot(purp.weights, aes(x = weight)) + geom_dotplot(binwidth = 30)
```

First, we filtered the complete dataset so that only the observations corresponding to the purple morph were retained, then we used `ggplot` with the dotplot geom to construct the figure we wanted. Once again (just as a reminder), here is how to achieve the same thing using the `%>%` operator:
```{r, fig.keep = FALSE}
morph.weights %>% 
  filter(pmorph == "purple") %>% 
  ggplot(aes(x = weight)) + geom_dotplot(binwidth = 30)
```

You should always explore your data visually before carrying out any kind of statistical analysis of it. You might learn something new about it, and at the very least, this allows you to assess whether there are any problems with it. A quick inspection of this figure suggests that there is nothing odd about the dry weight data. We only have 25 observations, so we can't say too much about its shape, but there don't seem to be any outliers. 

We are going to focus on just the purple morph data from now on. Let's return to our original question: How do we characterise the precision of the estimated mean dry weight of purple morphs (658 grams)?

### A resampling approach {}

In order to answer that last question we need to work out the **sampling distribution** associated with our estimate of the mean dry weight. At first glance, this seems like an impossible task, as we only have a single sample to work with. The solution to this problem is actually very simple (though subtle). We use the sample to approximate certain aspects of the population, and then work out what the sampling distribution of our focal estimate (statistic) looks like using this approximation. 

There are different ways to do this. One of the simplest methods--for easy problems at least--is to pretend that *the sample is the true population*. We can then draw new estimates of the mean from this 'population'. That may sound like cheating, but it turns out that this is very often a pefectly valid way to construct a sampling distribution for a statistic like the mean. 

Here is how it works. Imagine that we had written down each purple individual's weight on a different piece of paper, and placed all of these in a hat. We then do the following:

1. Pick a piece of paper at random, record its value, and then put the paper back into the hat.
2. Pick another piece of paper at random (you might get the same one), record its value, and then put that back into the hat.
3. Repeat this process until you have a recorded new sample which is of the same size as your real sample.

(This process is called 'sampling with replacement'. Each artificial sample is called a 'bootstrapped sample')

4. Repeat the process of sampling with replacement until we have generated a large number of bootstrapped samples. 10000 is often sufficient.
5. For each bootstrapped sample, calculate whatever statistic is of interest (i.e. the mean dry weight of purple morph plants in this case).

Although it may seem like cheating, this process really does produce an approximation of the sampling distribution of our focal statistic. It is called **bootstrapping**. Here is how to implement it in R to construct a sampling distribution for the estimated dry weight of purple morphs (no hats or paper required):
```{r}
purp.weights <- filter(morph.weights, pmorph == "purple")$weight 
boot.samp <- replicate(10000, mean(sample(purp.weights, replace = TRUE)))
```
All we did here was extract the sample of purple morph dry weights---using `filter` to subset the data, and `$` to grab the `weights` column---and then use functions called `sample` and `replicate` to generate a bootstrapped sampling distribution for the mean (we generated 10000 samples). You don't have to understand this R code, but ask a demonstrator if you want to know more about it. 

Let's take a quick look at the first 10 values:
```{r}
round(head(boot.samp, 10))
```
These numbers represents different values of the sample mean that we would expect to generate if we repeated the data collection exercise. We can use this bootstrapped sampling distribution in a number of ways. As always, it is a good idea to plot it first get a sense of what it looks like. A histogram is a good choice here, because we have a large number of samples:
```{r}
plot.df <- data.frame(boot.samp) # 'ggplot' expects a data frame 
ggplot(plot.df, aes(x = boot.samp)) + geom_histogram(binwidth = 5) 
```

The mean of the sampling distribution looks to be round about 655 grams--very close to the sample mean. We can of course calculate this in R: 
```{r}
round(mean(boot.samp))
```
This is the same as the sample statistic (the sample mean, in this case). This will always be the case if we construct a large enough sample, as the bootstrapping procedure assumes that the 'true' population mean is equal to the sample mean.

A more useful quantity is the bootstrapped standard error (SE). Since this is the standard deviation of the sampling distribution, we just apply the `sd` function to the bootstrap sampling distribution to calculate it:
```{r}
round(sd(boot.samp), 1)
```
This quantity is a standarised measure of uncertainty that we require. A large SE implies that our sample size was too small to reliably estimate the population mean. Whenever we report a point estimate of a mean, we should also report the standard error. For example,

> The mean dry weight biomass of purple morph plants (n = 25) was 658 grams (s.e. ± 22.3). 

Notice that we also report the sample size.

<div class="exercise-box">
#### Exercise: How big does a bootstrap sample need to be?
<div class="box-text">
Use the R code above to investigate how large a bootstrap sample needs to be to reliably estimate the standard error. Start with a bootstrap sample size of 10, and gradually increase it, calculating the standard error each time you do so. How many bootstrap samples are needed to reliably estimate the SE to one decimal place?
</div>
</div>

The bootstrap is a very powerful tool in the right hands. The bootstrap is actually quite an advanced technique that can be difficult to apply in many settings (e.g. analysis of complex experiments). It is for this reason that we will not apply it routinely in this course. We were mostly interested in using it to understand how 'frequentist' ideas can be used to quantify uncertainty in a point estimate. The key message for you to take away is that we can characterise uncertainty by working out what would happen under repeated sampling from a particular population. 

### A parametric approach {}

Most of the statistical tools that we will teach you in this course reply on what we might call **parameteric statistics**. Here, the word 'parametric' refers to the fact that the statistical models and tests that we will learn to use have at their heart some kind of mathematical model of the population. The precise details of the models are defined by their parameters. We aren't going to study these models in any great detail, because not everyone on this course has enough of a mathematical background to do this. We will talk about the assumptions of the underlying models though. 

Let's return to our example. In order to construct our bootstrap sampling distribution we pretended that the sample was the true population. A 'parametric' version of this procedure starts by making an assumption about the mathematical form of the population distribution of focal variable. We then use estimates of the parameters which describe the population to understand what would happen if we were to repeatedly resample it. Those estimates are derived from the sample.

In this course, this assumption is essentially always the same: we assume that the variable follows a **normal distribution**. If you studied A-level statistics you will know all about this. If not, you may have come across it without realising: the normal distribution is sometimes called the 'Gaussian distribution' or more colloquially, 'the bell-shaped curve'.

Unfortunately, we don't have enough time in this course to really study the normal distribution in much detail. There are however, many good online resources to help you learn you about it if you want to know more. Here is one relatively non-technical introduction:

http://onlinestatbook.com/2/normal_distribution/normal_distribution.html

So what can we say about the standard error of the sample mean, when it is calculated for a normally distributed variable? It turns out, that when we resample from a normally distributed variable, there is a very simple formula for the standard error of the mean. Here it is:
$$
SE = \frac{\text{Standard deviation of the sample}}{\sqrt{\text{Sample size}}} = \frac{SD}{\sqrt{n}}
$$
Notice that this only depends on the properties of the original sample, that is, the sample standard deviation and the sample size. This means that as long as we are happy with the normality assumption, we can go ahead and calculate a standard error for a point estimate of the mean without resorting to fancy tools like the bootstrap. Here is how to do this using R: 
```{r}
n <- length(purp.weights) # get the sample size
round(sd(purp.weights)/sqrt(n), 1)
```
That's all we need to do. This returns a value of 22.8, which is reassuringly close to the bootstrapped value of 22.3. They aren't identical, because each estimate of the SE relies on a different procedure, but they are very close.
