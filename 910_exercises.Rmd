# (APPENDIX) Supplementary Material {-} 

# Exercises 

## Data and variables

### What kind of variable is it?

The following table gives a number of measurements taken in the course of a study of a woodland ecosystem. What type of variable results from the measurements taken in each case?

```{r, echo = FALSE}
table_data <- read.csv(file = "./tables_csv/variable_types.csv")
knitr::kable(
  table_data, booktabs = TRUE,
  caption = 'Examples of different kinds of variable.'
)
```



## Statistical concepts

### Sampling distributions

Spend a few minutes looking at the distribution of purple morph counts we simulated. See if you can answer the following questions:

*   What is the most common purple morph count we should expect to find in a sample of 20 individuals, when the population frequency is thought to be 40%?

*   Imagine someone told you that they thought 40% of the plants were purple. If you sampled 20 individuals and found that 4 of them were purple, would you be convinced of their assertion? What if you found only 2 purple plants?

#### How does sample size influence the standard error?

Think back to the purple morph / green morph example. We can use a simulation in R to calculate the (approximate) standard error of purple morph frequencies. For example, if we want to know the standard error when we use a sample size of 20, and the purple morph frequency is 40% (i.e., the proportion of purple morph plants is 0.4), we can use this snippet of R code:
```{r}
purple.prob <- 0.4
sample.size <- 20
samples <- 100 * rbinom(n = 100000, size = sample.size, prob = purple.prob) / sample.size
sd(samples)
```
You **do not** have to understand exactly how this works. If you did A-level statistics you might be able to guess what the `rbinom` function is doing. Essentially, what we did was to simulate the percentage of purple morph individuals found in 100000 samples of 20 individuals (stored in `samples`), and then used the `sd` function to calculate the standard error--remember, the standard error is the standard deviation of the sampling distribution of a statistic (= morph frequency). Ask a demonstrator if you want to know more. We just want you to use this R code to do the next exercise.

Use the above code to vary the sample size from 20 to 320, doubling the sample size each time (i.e., use samples of 20, 40, 80, etc). You only need to vary the value of `sample.size` to do this. Make sure you do this in your script, not at the command line. If you are feeling ambitious, store the results of your investigation in a data frame and use `ggplot2` to help you visualise them. You don't have to do this though; it is fine just to write down the numbers.

See if you can work out how the standard error changes as the sample size increases. Does the standard error halve when you double the sample size, or is the relationship more complicated? If you think the relationship is more complicated, what form does it take?

ANSWER:

The more important insight relates to the form of this relationship. What you should have noticed is that doubling the sample size does not halve the standard error. In fact, doubling the sample size only changes the standard error by a factor of 1/âˆš2, which is less than 1/2 (don't worry if you did not spot this).

The somewhat depressing conclusion from this investigation is that we have to increase the size of a sample by a factor of 4 to halve the uncertainty associated with an estimate of a population parameter. This result isn't a peculiarity of the morph frequency example; it is very general.

### How big does a bootstrap sample need to be?

Use the R code above to investigate how large a bootstrap sample needs to be to reliably estimate the standard error. Start with a bootstrap sample size of 10, and gradually increase it, calculating the standard error each time you do so. How many bootstrap samples are needed to reliably estimate the SE to one decimal place?

## Simple comparisons

## Regression

