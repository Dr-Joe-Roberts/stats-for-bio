# Standard error

## A quick recap

FINISH ME

## The standard error

We were fairly relaxed about how we quantified the variability of a sampling distribution in the last chapter. All we did was extract the approximate range of purple morph counts "by eye". This is fine for investigating general patterns, but to make rigorous comparisons, we really need a quantitative measure of this variability. It is called the **standard error**. 

The standard error is actually quite a simple idea, but its definition can be confusing. We'll give the definition, and then see one way to apply it to simulated data. Here is the definition: the standard error is the standard deviation of the sampling distribution of a statistic such as a mean (or frequency). Don't worry if that makes absolutely no sense yet. It is a standard deviation, so it quantifies the expected spread, or dispersion, of the sampling distribution.

(Note that it is common to use a shorthand abbreviations ("SE", "se" or "s.e") in place of 'standard error' when refering to it in text.)

We can use a simulation in R to calculate the approximate standard error of a estimates of purple morph frequencies. Let's assume we want to know the standard error when we use a sample size of 20, and the purple morph frequency is 40% (i.e., the proportion of purple morph plants is 0.4). we can use this snippet of R code:
```{r}
purple_prob <- 0.4
sample_size <- 20
raw_samples <- rbinom(n = 100000, size = sample_size, prob = purple_prob)
percent_samples <- 100 * raw_samples / sample_size
sd(percent_samples)
```
You **do not** have to understand exactly how this works, but if you did A-level statistics you might be able to guess what the `rbinom` function is doing. Essentially, what we did was to simulate the percentage of purple morph individuals found in 100000 samples of 20 individuals (stored in `samples`), and then used the `sd` function to calculate the standard error--remember, the standard error is the standard deviation of the sampling distribution of a statistic (= morph frequency). Ask a demonstrator if you want to know more. We just want you to use this R code to do the next exercise.

This exercise should also have convinced you that the standard error decreases as the sample size is increased. We'll look a little more closely at the form of this relationship in one of the practical exercises.

## Calculating the SE: A parametric approach {#se-bootstrap}

```{r, echo = FALSE, eval = FALSE}
set.seed(27081975)
nsample <- 25
prpszs <- rnorm(nsample, mean = 700, sd = 150) + 20
grnszs <- rnorm(nsample, mean = 740, sd = 160) 

pmorph <- c("purple","green")[rep(1:2, each = nsample)]
morph.weights <- data.frame(pmorph = pmorph, 
                             weight = round(c(prpszs, grnszs)))

write.csv(morph.weights, row.names = FALSE,
          file = "./course-data/MORPH_WEIGHTS.CSV")
```

By this point you might (quite reasonably) be wondering why we have spent so much time looking at the properties of repeated samples from a population with **known** parameters. After all, when we collect real data we only have a single sample to work with. We also won't know much about the population parameter of interest; this lack of knowledge is the reason for collecting the data in the first place!

The short answer to this question is that we want to learn how to use '**frequentist inference**' in this course. The word 'inference' is just statistical jargon for the process of learning about a system using data. A precise definition of what constitutes frequentist inference is well beyond the scope of this course, but we can give a rough description. Frequentist inference works by asking *what would have happened* if we were to repeat an experiment or data collection exercise many times, assuming that the a population parameter is fixed at a particular value. The precise choice of population parameter to use, and its 'particular value', will depend on what kind of question you are asking of the data.

### A new example {}

In order to get a sense of how all this works, we are going to finish this chapter by trying to address a very simple question: How precise is an estimate of the population mean? We'll look at this question in two different ways, both of which rely on 'frequentist' ideas.

Once again, we'll investigate the problem by working through a simple example. We will stay with the purple morph / green morph example, but this time we'll examine a different variable: the dry weight biomass of our imaginary plants. Perhaps we suspect that the two morphs have different growth habits. One way to address this hypothesis would be to measure the biomass of individuals of each morph (though arguably, this is a little naive). Ultimately, we want to compare the biomass of each morph, but that is the goal of the next practical. Today, we'll just see how to quantify uncertainty in a single estimate of the population mean biomass of each morph.

In order to study the biomass of individuals in our hypothetical population, we would collect a sample of dry weights. Dry weight is a numeric variable, measured on a ratio scale. The population parameters of interest now are the population mean dry weights of each morph. Notice that our definition of 'the population' is slightly different than before. Now we are imagining that each morph is a seperate population. Let's assume that we have sampled the dry weight (in grams) of 25 representative individuals of each morph.

We have have generated a dataset to represent this situation, stored in a Comma Seperated Value (CSV) text file called 'MORPH_WEIGHTS.CSV'. 

<div class="exercise-box">
#### Exercise: Investigate the dataset
<div class="box-text">
Download the MORPH_WEIGHTS.CSV file from MOLE and place it in your working directory (this is the location you set at the beginning of this practical). Next, make sure that you can do the following:

* Read the data in MORPH_WEIGHTS.CSV into an R data frame using `read.csv`, assigning the data frame the name `morph.weights`.

(Hint: Use RStudio to help you do this. In the 'Environment' tab there is a dropdown menu called 'Import Dataset'. Click on this, select 'From Text File...', click on the MORPH_WEIGHTS.CSV file, and then then change the suggested name to 'morph.weights'. You should then need to copy the `read.csv` command that RStudio sends to the Console into your script.)

* Use the `glimpse` function from `dplyr` to inspect the structure of `morph.weights`. How many variables are in the dataset. What are their names? What kind of variables are they?

* Use the `View` function to inspect the data. How many rows are in the dataset--does this number make sense to you? Are the values of the different variables as you would expect them to be?
</div>
</div>

```{r, echo = FALSE}
morph.weights <- read.csv(file = "./data_csv/MORPH_WEIGHTS.CSV")
```

We read in the data and then carried out a few 'sanity checks' in that last exercise. **Always check your data after you have read it in**. There is no point messing about with the likes of `dplyr` and `ggplot2`, or carrying out a statistical analysis, until we have done this. If we don't understand how our data is organised, there is very real risk that we will make a lot of easily avoidable mistakes.

The next step is to calculate some simple descriptive statistics for each morph. We need to know the sample means--these are our 'best guesses' of the population means--and it may be useful to know something about the variability of the samples. The sample standard deviation is a good measure of the latter. Here is a reminder of how to do this using `dplyr`:
```{r}
temporary <- group_by(morph.weights, pmorph)
summarise(temporary, mean = mean(weight), stan.dev = sd(weight))
```
This shows that the mean dry weights of purple and green morphs are 658 grams and 787 grams, respectively. The standard deviation estimates from the two samples suggest that dry weights of green morphs are a little more variable than the purple morphs. 

By the way, if you like using the `%>%` operator to chain together `dplyr` functions (the 'verbs'), then here is how to use this to achive exactly the same result as above:
```{r}
morph.weights %>% 
  group_by(pmorph) %>% 
  summarise(mean = mean(weight), stan.dev = sd(weight))
```

Using means and standard deviations to summarise samples can be tricky to understand until you are used to them. A plot of some kind is much more useful. At the moment, we are just trying to understand the distribution of our two samples. One way to do this is to construct a histogram or a dotplot of each sample distribution. We don't have much data, so a dotplot is probably the best option. Here is one way to make a dot plot for just the purple morph data:
```{r purple-dist}
purp.weights <- filter(morph.weights, pmorph == "purple") 
ggplot(purp.weights, aes(x = weight)) + geom_dotplot(binwidth = 30)
```

First, we filtered the complete dataset so that only the observations corresponding to the purple morph were retained, then we used `ggplot` with the dotplot geom to construct the figure we wanted. Once again (just as a reminder), here is how to achieve the same thing using the `%>%` operator:
```{r, fig.keep = FALSE}
morph.weights %>% 
  filter(pmorph == "purple") %>% 
  ggplot(aes(x = weight)) + geom_dotplot(binwidth = 30)
```

You should always explore your data visually before carrying out any kind of statistical analysis of it. You might learn something new about it, and at the very least, this allows you to assess whether there are any problems with it. A quick inspection of this figure suggests that there is nothing odd about the dry weight data. We only have 25 observations, so we can't say too much about its shape, but there don't seem to be any outliers. 

We are going to focus on just the purple morph data from now on. Let's return to our original question: How do we characterise the precision of the estimated mean dry weight of purple morphs (658 grams)?

### A resampling approach {}

In order to answer that last question we need to work out the **sampling distribution** associated with our estimate of the mean dry weight. At first glance, this seems like an impossible task, as we only have a single sample to work with. The solution to this problem is actually very simple (though subtle). We use the sample to approximate certain aspects of the population, and then work out what the sampling distribution of our focal estimate (statistic) looks like using this approximation. 

There are different ways to do this. One of the simplest methods--for easy problems at least--is to pretend that *the sample is the true population*. We can then draw new estimates of the mean from this 'population'. That may sound like cheating, but it turns out that this is very often a pefectly valid way to construct a sampling distribution for a statistic like the mean. 

Here is how it works. Imagine that we had written down each purple individual's weight on a different piece of paper, and placed all of these in a hat. We then do the following:

1. Pick a piece of paper at random, record its value, put the paper back into the hat, and shake the hat about to mix up the bits of paper.

2. Pick another piece of paper at random (you might get the same one), record its value, and then put that back into the hat, remembering to sake everything up.

3. Repeat this process until you have a recorded new sample which is of the same size as your real sample.

(This process is called 'sampling with replacement'. Each artificial sample is called a 'bootstrapped sample')

4. Repeat the process of sampling with replacement until we have generated a large number of bootstrapped samples. 10000 is often sufficient.

5. For each bootstrapped sample, calculate whatever statistic is of interest (i.e. the mean dry weight of purple morph plants in this case).

Although it may seem like cheating, this process really does produce an approximation of the sampling distribution of our focal statistic. It is called **bootstrapping**. 

Here is how to implement it in R to construct a sampling distribution for the estimated dry weight of purple morphs (no hats or paper required):
```{r}
purp.weights <- filter(morph.weights, pmorph == "purple")$weight 
boot.samp <- replicate(10000, mean(sample(purp.weights, replace = TRUE)))
```
All we did here was extract the sample of purple morph dry weights---using `filter` to subset the data, and `$` to grab the `weights` column---and then use functions called `sample` and `replicate` to generate a bootstrapped sampling distribution for the mean (we generated 10000 samples). You don't have to understand this R code, but ask a demonstrator if you want to know more about it. 

Let's take a quick look at the first 10 values:
```{r}
round(head(boot.samp, 10))
```
These numbers represents different values of the sample mean that we would expect to generate if we repeated the data collection exercise. We can use this bootstrapped sampling distribution in a number of ways. As always, it is a good idea to plot it first get a sense of what it looks like. A histogram is a good choice here, because we have a large number of samples:
```{r}
plot.df <- data.frame(boot.samp) # 'ggplot' expects a data frame 
ggplot(plot.df, aes(x = boot.samp)) + geom_histogram(binwidth = 5) 
```

The mean of the sampling distribution looks to be round about 655 grams--very close to the sample mean. We can of course calculate this in R: 
```{r}
round(mean(boot.samp))
```
This is the same as the sample statistic (the sample mean, in this case). This will always be the case if we construct a large enough sample, as the bootstrapping procedure assumes that the 'true' population mean is equal to the sample mean.

A more useful quantity is the bootstrapped standard error (SE). Since this is the standard deviation of the sampling distribution, we just apply the `sd` function to the bootstrap sampling distribution to calculate it:
```{r}
round(sd(boot.samp), 1)
```
This quantity is a standarised measure of uncertainty that we require. A large SE implies that our sample size was too small to reliably estimate the population mean. Whenever we report a point estimate of a mean, we should also report the standard error. For example,

> The mean dry weight biomass of purple morph plants (n = 25) was 658 grams (s.e. ± 22.3). 

Notice that we also report the sample size.

The bootstrap is a very powerful tool in the right hands. The bootstrap is actually quite an advanced technique that can be difficult to apply in many settings (e.g. analysis of complex experiments). It is for this reason that we will not apply it routinely in this course. We were mostly interested in using it to understand how 'frequentist' ideas can be used to quantify uncertainty in a point estimate. The key message for you to take away is that we can characterise uncertainty by working out what would happen under repeated sampling from a particular population. 

## Calculating the SE: A parametric approach {#se-parametric}

Most of the statistical tools that we will teach you in this course reply on what we might call **parameteric statistics**. The word 'parametric' refers to the fact that most of the statistical models and tests that we will learn about are based on some kind of mathematical model of the population. The precise details of the models are defined by their parameters. We aren't going to study these models in any great detail, because this is supposed to be a practical course.

(We will talk about the assumptions of the underlying models though. You are important and should not be ignored)

Let's return to our example. In order to construct our bootstrap sampling distribution we pretended that the sample was the true population. A 'parametric' version of this procedure starts by making an assumption about the mathematical form of the population distribution of focal variable. We then use estimates of the parameters which describe the population to understand what would happen if we were to repeatedly resample it. Those estimates are derived from the sample.

In this course, this assumption is essentially always the same: we assume that the variable follows a **normal distribution**. If you studied A-level statistics you will know all about this. If not, you may have come across it without realising: the normal distribution is sometimes called the 'Gaussian distribution' or more colloquially, 'the bell-shaped curve'.

Unfortunately, we don't have enough time in this course to really study the normal distribution in much detail. There are however, many good online resources to help you learn you about it if you want to know more. Here is one relatively non-technical introduction:

http://onlinestatbook.com/2/normal_distribution/normal_distribution.html

So what can we say about the standard error of the sample mean, when it is calculated for a normally distributed variable? It turns out, that when we resample from a normally distributed variable, there is a very simple formula for the standard error of the mean. Here it is:
$$
SE = \frac{\text{Standard deviation of the sample}}{\sqrt{\text{Sample size}}} = \frac{SD}{\sqrt{n}}
$$
Notice that this only depends on the properties of the original sample, that is, the sample standard deviation and the sample size. This means that as long as we are happy with the normality assumption, we can go ahead and calculate a standard error for a point estimate of the mean without resorting to fancy tools like the bootstrap. Here is how to do this using R: 
```{r}
n <- length(purp.weights) # get the sample size
round(sd(purp.weights)/sqrt(n), 1)
```
That's all we need to do. This returns a value of 22.8, which is reassuringly close to the bootstrapped value of 22.3. They aren't identical, because each estimate of the SE relies on a different procedure, but they are very close.
