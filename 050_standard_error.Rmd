# Sampling variation and standard errors

[[PREAMBLE]]

```{r plant-sim-par, echo=FALSE}
set.seed(27081975)
nsamp <- 200
sampsize1 <- 20
sampsize2 <- 40
sampsize3 <- 80
index <- c(1,1,2,2,2)
prop.purp <- sum(index==1)/length(index)
```

... we can use the machinery of statistics to help us quantify this uncertainty. Once we know something about the uncertainty of an estimate we can start to ask questions of the sort we discussed. However, before we can use these tools we first need to understand something called sampling error. The rest of this chapter will give you a flavour of this really important idea.

The easiest way to get a sense of how population parameters, point estimates and sampling error are related to one another is by working with a concrete example. Rather than collecting real data, we're going to use a computer simulation. A simulation is just an imitation of a real-world process. The advantage of using a simulation is that it allows us to study many different realisations of the same process. We'll see why that is important soon.

## The example {#morph-example}

Let's study a very simple example. Imagine we are working on a plant species that is polymorphic. There are two different morphotypes ('morphs'), and to keep life simple we'll refer to them as the purple morph and the green morph. The statistical population we're interested in is therefore a biological population of plants. We can depict this situation visually with a map showing where the purple and green individuals are located on a hypothetical landscape:

```{r plants-all, echo = FALSE, out.width='50%', fig.asp=1, fig.align='center', fig.cap='Landscape showing the position of purple and green morphs'}
plantdata <- 
  data.frame(xloc  = runif(nsamp), 
             yloc  = runif(nsamp), 
             morph = sample(c("purple","green")[index], 100, replace = TRUE))
plttheme <- theme_get()
plttheme$axis.text <- plttheme$axis.ticks <- plttheme$axis.title <- element_blank()
baseplt <- ggplot(plantdata, aes(x = xloc, y = yloc, colour = morph, )) + 
           geom_point() + scale_color_identity() + coord_fixed() + plttheme
baseplt
```

These artificial, idealised data were generated using R. We placed 'individuals' onto the landscape at random locations---every location is equally likely---and then assigned them purple morph status with a certain probability; we made them are green otherwise. In fact, we used a probability of 0.4 to assign the purple morph status. Of course, in a real world setting we wouldn't know this.

## The question, variable, and population parameter

Let's proceed as though this were a real situation. 

[[Question]]

To study plant morphotype we need to collect information about the colour of different individuals. This means we are working with a nominal variable, taking values 'purple' or 'green'. That's step two complete: we've decided on the variable we need to study.

The prediction we want to test is about the purple morph frequency. The population parameter of interest is therefore, the morph frequency (or equivalently, the percentage or proportion). That's step three done: we've decided on the population parameter we're interested in.

## Sampling error and sampling distributions

In contrast to a real-world setting, we already know the true value of the population parameter in this example. The purple morph frequency is 40%. In the real world this is the parameter we'd be trying to estimate. If we weren't able to sample every individual, we would have to construct some kind of point estimate of the purple morph frequency. To do this, we would take a representative sample of plants from across the landscape and then calculate the percentage of purple plants in our sample. 

A representive sample in this case is one in which every individual has an equal probability of being sampled. We call this a **random sample**. Gathering a random sample of organisms from across a landscape is surprisingly hard to do in reality. Luckily it is easy to at least simulate a random sample.

Let's seen what happens if we sample `r sampsize1` plants in this way. This plot shows the original population of plants, but now we have circled the selected individuals in red.
```{r plants-samp1, echo = FALSE, out.width='50%', fig.asp=1, fig.align='center', fig.cap='Plants sampled on the first occasion'}
sample1 <- sample_n(plantdata, size = sampsize1)
baseplt + geom_point(data = sample1, colour = "red", shape = 1, size = 5)
freqs1 <- table(sample1$morph)
```
We found `r freqs1["green"]` green plants and `r freqs1["purple"]` purple plants in this first hypothetical sample, which means our estimate of the purple morph frequency is `r round(100*freqs1["purple"]/sampsize1)`%. This is not far off the true value of 40%. What happens if we repeat this process, resulting in a new, completely independent sample? Here is the sampled population:
```{r plants-samp2, echo = FALSE, out.width='50%', fig.asp=1, fig.align='center', fig.cap='Plants sampled on the second occasion'}
sample2 <- sample_n(plantdata, size = sampsize1)
baseplt + geom_point(data = sample2, colour = "red", shape = 1, size = 5)
freqs2 <- table(sample2$morph)
```
This time we ended up sampling `r freqs2["green"]` green plants and `r freqs2["purple"]` purple plants, so our new estimate of the purple morph frequency is `r round(100*freqs2["purple"]/sampsize1)`%, which is quite some way off the true value.

Nothing about the study population changed between the first and second sample. What's more, we used a completely reliable sampling scheme to generate these samples; there is nothing biased or 'incorrect' about the way individuals were sampled. The different estimates of the purple morph frequency arise from nothing more than chance variation.

This chance variation--which arises whenever we observe a sample instead of the whole population--has a special name. It is called the **sampling error** (or sampling variation). Sampling error is the main reason we have to use statistics to learn from data. It is always present, and so any estimate you derive from a sample is affected by it. Sampling error is not a property of any particular sample. It is really a property of the population distribution of the focal variable, and the sampling method used to investigate this. That statement may seem a little cryptic now, but we will start to get a sense of what it means in this, and the next, practical.

We can develop our simple simulation example to explore the consequences of sampling error. Rather than taking one sample at a time, we will use R to simulate 1000s of different samples, and for each sample, calculate the number of purple morph individuals found. Each sample is drawn from the same population, i.e., the population parameter (purple morph frequency) is the same for every sample. Here is a summary of one such repeated simulation exercise:
```{r samp-dist-1, echo = FALSE, out.width='80%', fig.asp=0.6, fig.align='center', fig.cap='Distribution of number of purple morphs sampled (n = 20)'}
out <- data.frame(n.purple = factor(rbinom(n = 100000, size = sampsize1, prob = prop.purp)))
ggplot(out, aes(x = n.purple)) + geom_bar() + 
  scale_x_discrete(limits = as.character(0:sampsize1)) + 
  xlab("No. of purple morph individuals") + ylab("Count")
```

This bar plot summarises the result from 100000 samples. In each sample, we took `r sampsize1` individuals from our hypothetical population and calculated the number of purple morphs found. The bar plot shows the number of times we found 0, 1, 2, 3, ... purple individuals, all the way up to the maximum possible (`r sampsize1`). It summarises the distribution of purple morph counts that we can expect when we repeat the same sampling process over and over again.

This distribution has a special name. It is called the **sampling distribution**. The sampling distribution is just the distribution we expect a particular statistic to follow. In order to to work this out, we have to postulate values for the population parameters, and we have to know how the population was sampled. We just used simulation to approximate the sampling distribution of purple morph counts that arises when we sample `r sampsize1` individuals from a population that is `r 100*prop.purp`% purple. 

The sampling distribution is the key to 'doing statistics'.  

Once we know how to calculate the sampling distribution for a particular problem, we can start to make statements about sampling error (to quantify uncertainty), and we can begin to make meaningful comparisons that enable us to address scientific questions. Fortunately, we don't have to work any of this out for ourselves. Statisticians have already done this for many different situations.

### The effect of sample size

Perhaps the most important property of any sampling scheme is the **sample size**: the number of observations (objects or items) in a sample. To see how sample size influences the sampling distribution, and to understabnd why it matters, let's carry on with our simulation example. We will repeat the resampling exercise, but this time we will do it twice, first taking a sample of `r sampsize2` individuals each time, and then taking a sample of `r sampsize3` individuals each time. In both cases, we'll examine the results of taking 100000 samples overall:

```{r samp-dist-2, echo = FALSE, out.width='80%', fig.asp=0.6, fig.align='center', fig.cap='Distribution of number of purple morphs sampled (n = 40)'}
out <- data.frame(n.purple = factor(rbinom(n = 100000, size = sampsize2, prob = prop.purp)))
ggplot(out, aes(x = n.purple)) + geom_bar() + 
  scale_x_discrete(limits = as.character(seq(0, sampsize2, 1)), 
                   breaks = as.character(seq(0, sampsize2, 2))) + 
  xlab("No. of purple morph individuals") + ylab("Count")
```

```{r samp-dist-3, echo = FALSE, out.width='80%', fig.asp=0.6, fig.align='center', fig.cap='Distribution of number of purple morphs sampled (n = 80)'}
out <- data.frame(n.purple = factor(rbinom(n = 100000, size = sampsize3, prob = prop.purp)))
ggplot(out, aes(x = n.purple)) + geom_bar() + 
  scale_x_discrete(limits = as.character(seq(0, sampsize3, 1)), 
                   breaks = as.character(seq(0, sampsize3, 4))) + 
  xlab("No. of purple morph individuals") + ylab("Count")
```

What do these plots tell us about the effect of increasing sample size? Notice that we plotted each of them over the full range of possible outcomes (the x axis runs from 0-`r sampsize2` and 0-`r sampsize3`, respectively, in the first and second plot). We did this so that we can meaningfully compare the spread of each sampling distribution, relative to the full range of possible outcomes.

What do these figures show? The range of outcomes in the first plot is roughly 6 to 26, which corresponds to estimated frequencies of the purple morph in the range of 15-65% (we sampled 40 individuals each time). The range of outcomes in the second plot is roughly 16 to 48, which corresponds to estimated frequencies in the range of 20-60%. Clearly, this suggests that when we increase the sample size we expect to encounter less sampling error. This makes intuitive sense: the composition of large sample should more closely approximate that of the true population than a small sample. 

How much data do we need to collect to accurately estimate a frequency? Here is the approximate sampling distribution of the purple morph frequency estimate when we sample `r (sampsizebig <- 500)` individuals each time we take a sample: 
```{r samp-dist-big, echo = FALSE, out.width='80%', fig.asp=0.6, fig.align='center', fig.cap='Distribution of number of purple morphs sampled (n = 500)'}
out <- data.frame(n.purple = factor(rbinom(n = 100000, size = sampsizebig, prob = prop.purp)))
ggplot(out, aes(x = n.purple)) + geom_bar() + 
  scale_x_discrete(limits = as.character(seq(0, sampsizebig, 1)), 
                   breaks = as.character(seq(0, sampsizebig, 50))) + 
  xlab("No. of purple morph individuals") + ylab("Count")
```

Now the range of outcomes is about 160 to 240, corresponding to purple morph frequencies in the 32-48% range. This is a big improvement over the smaller samples that we just considered, but even with 500 individuals in a sample, we should still expect quite a lot of uncertainty in our estimate. The take home message is that you need a lot of data to reduce sampling error.

## The standard error

We were fairly relaxed about how we quantified the variability of a sampling distribution in the last chapter. All we did was extract the approximate range of purple morph counts "by eye". This is fine for investigating general patterns, but to make rigorous comparisons, we really need a quantitative measure of this variability. It is called the **standard error**. 

The standard error is actually quite a simple idea, though its definition sometimes confuses people. Here is the definition: the standard error is the standard deviation of the sampling distribution of an estimate (such as a mean or frequency). Don't worry if that makes absolutely no sense yet. The key point is that it is a standard deviation, so it quantifies the expected spread, or dispersion, of the sampling distribution.

(Note that it is common to use a shorthand abbreviations ("SE", "se" or "s.e") in place of 'standard error' when refering to it in text.)

We can use a simulation in R to calculate the expected standard error of an estimate of purple morph frequency. Let's assume we want to know the expected standard error when we use a sample size of 100 and the purple morph frequency is 40%. We can use this snippet of R code to generate 10000 samples :
```{r}
purple_prob <- 0.4
sample_size <- 100
n_samples <- 100000
raw_samples <- rbinom(n = n_samples, size = sample_size, prob = purple_prob)
percent_samples <- 100 * raw_samples / sample_size
```
This is the same R code we used to generate those histograms above. The only difference is that we converted the numbers sampled into proportions. You don't have to understand how this works, though if you did A-level statistics you might be able to guess what the `rbinom` function is doing. Really, the R code isn't important here. The result is what matters: we just simulated the percentage of purple morph individuals found in 100000 samples of 20 individuals, storing the result in a vector called `percent_samples`. Here are the first 50 values:
```{r}
head(percent_samples, 50)
```
How do calculate the required standard error? The standard error is the standard deviation of these numbers, so we just use the `sd` function:
```{r}
sd(percent_samples)
```
What does this tell us?

[[FINISH ME]]

## A quick recap

[[FINISH ME]]

By this point you might (quite reasonably!) be wondering why we have spent so much time looking at the properties of repeated samples from a population with **known** parameters. After all, when we collect real data we only have a single sample to work with and we don't know much about the population parameter of interest. This lack of knowledge is the reason for collecting the data in the first place!

The short answer to this question is that we want to learn how to use '**frequentist inference**' in this course. A precise definition of what constitutes frequentist statistics is well beyond the scope of this course, but we can give a rough description. Frequentist inference works by asking *what would have happened* if we were to repeat an experiment or data collection exercise many times, assuming that the a population parameter never changes.

[[FINISH ME]]

## Estimating the standard error {#se-bootstrap}

In order to answer that last question we need to work out what the **sampling distribution** purple morph frequency estimate looks like. At first glance, this seems like an impossible task when we only have a single sample to work with. One solution to this problem is surprisingly simple: we use the sample to approximate certain aspects of the population, and then work out what the sampling distribution of our focal estimate  looks like using this approximation.

Let's unpack this idea, and then try it out for real.

### The bootstrap {}

There are many different ways to approximate a population from a sample. One of the simplest methods---for easy problems at least---is to pretend *the sample is the true population*. We then draw new samples from this pretend population. That may sound a lot like cheating, but it turns out that this is a perfectly valid way to construct a sampling distribution for many different kinds of estimates. 

Here is how it works. Imagine that we had written down each sampled individual's colour on a different piece of paper, and placed all of these in a hat. We then do the following:

1. Pick a piece of paper at random, record its value (purple or green), put the paper back into the hat, and shake the hat about to mix up the bits of paper.

2. Pick another piece of paper (you might get the same one), record its value, and then put that back into the hat, remembering to shake everything up.

(The shaking here is meant to ensure that each piece of paper has an equal chance of being picked. This might not work in reality of course.)

3. Repeat this process until you have a recorded new sample of colours which is the same size as your real sample.

(This process is called 'sampling with replacement'. Each artificial sample is called a 'bootstrapped sample'.)

4. For each bootstrapped sample, calculate whatever quantity is of interest (i.e. the proportion of purple morph plants sampled).

5. Repeat steps 1-4 until we have generated a large number of bootstrapped samples. 10000 is often sufficient.

Although it may seem like cheating (it's not!), this process really does produce an approximation of the sampling distribution of our quantity is of interest. It is called **bootstrapping**. 

### Doing it for real

Here is how to implement it in R to construct a sampling distribution for the estimated dry weight of purple morphs (no hats or paper required):
```{r}
purp.weights <- filter(morph.weights, pmorph == "purple")$weight 
boot.samp <- replicate(10000, mean(sample(purp.weights, replace = TRUE)))
```
All we did here was extract the sample of purple morph dry weights---using `filter` to subset the data, and `$` to grab the `weights` column---and then use functions called `sample` and `replicate` to generate a bootstrapped sampling distribution for the mean (we generated 10000 samples). You don't have to understand this R code, but ask a demonstrator if you want to know more about it. 

Let's take a quick look at the first 10 values:
```{r}
round(head(boot.samp, 10))
```
These numbers represents different values of the sample mean that we would expect to generate if we repeated the data collection exercise. We can use this bootstrapped sampling distribution in a number of ways. As always, it is a good idea to plot it first get a sense of what it looks like. A histogram is a good choice here, because we have a large number of samples:
```{r}
plot.df <- data.frame(boot.samp) # 'ggplot' expects a data frame 
ggplot(plot.df, aes(x = boot.samp)) + geom_histogram(binwidth = 5) 
```

The mean of the sampling distribution looks to be round about 655 grams--very close to the sample mean. We can of course calculate this in R: 
```{r}
round(mean(boot.samp))
```
This is the same as the sample statistic (the sample mean, in this case). This will always be the case if we construct a large enough sample, as the bootstrapping procedure assumes that the 'true' population mean is equal to the sample mean.

A more useful quantity is the bootstrapped standard error (SE). Since this is the standard deviation of the sampling distribution, we just apply the `sd` function to the bootstrap sampling distribution to calculate it:
```{r}
round(sd(boot.samp), 1)
```
This quantity is a standarised measure of uncertainty that we require. A large SE implies that our sample size was too small to reliably estimate the population mean. Whenever we report a point estimate of a mean, we should also report the standard error. For example,

> The mean dry weight biomass of purple morph plants (n = 25) was 658 grams (s.e. ± 22.3). 

Notice that we also report the sample size.

The bootstrap is a very powerful tool in the right hands. The bootstrap is actually quite an advanced technique that can be difficult to apply in many settings (e.g. analysis of complex experiments). It is for this reason that we will not apply it routinely in this course. We used it here to understand how 'frequentist' ideas can be used to quantify uncertainty in a statistic (i.e. a point estimate).

The key message to take away is that we can characterise uncertainty by working out what **would happen under repeated sampling** from a particular population. 

